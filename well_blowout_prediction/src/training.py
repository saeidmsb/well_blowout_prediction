import sys
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import pandas as pd  # Ù…Ø·Ù…Ø¦Ù† Ø´Ùˆ Ú©Ù‡ pandas Ù‡Ù… ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯

# Ù…Ø³ÛŒØ± models Ø±Ø§ Ø¨Ù‡ sys.path Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªØ§ Ø§ÛŒÙ…Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§ Ø¯Ø±Ø³Øª Ú©Ø§Ø± Ú©Ù†Ù†Ø¯
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'models')))

# Ø§ÛŒÙ…Ù¾ÙˆØ±Øª ØªØ§Ø¨Ø¹ load_sensor_data
from data_loader import load_sensor_data
from preprocessing import create_sequences
from lstm_model import LSTMModel  # Ø­Ø§Ù„Ø§ Ù…Ø¯Ù„ LSTM Ø§Ø² Ù¾ÙˆØ´Ù‡ models ÙˆØ§Ø±Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯
from cnn_model import CNNModel

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯Ø³ØªÚ¯Ø§Ù‡ (CPU/GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def train_model(data, sequence_length=50, model_type="LSTM", epochs=10, batch_size=32, learning_rate=0.001, hidden_layer_size=64):
    """
    Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ LSTM ÛŒØ§ CNN Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² PyTorch.
    """
    # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ data ÛŒÚ© Ø±Ø´ØªÙ‡ (Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„) Ø§Ø³Øª ÛŒØ§ ÛŒÚ© DataFrame
    if isinstance(data, str):  # Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ÛŒÚ© Ø±Ø´ØªÙ‡ (Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„) Ø¨Ø§Ø´Ù†Ø¯
        print("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Ù†ÙˆØ¹ Ø±Ø´ØªÙ‡ (Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„) Ù‡Ø³ØªÙ†Ø¯ØŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ CSV Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
        df = pd.read_csv(data)  # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² ÙØ§ÛŒÙ„ CSV
    elif isinstance(data, pd.DataFrame):  # Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Ù†ÙˆØ¹ DataFrame Ø¨Ø§Ø´Ù†Ø¯
        df = data
    else:
        raise ValueError("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ ÛŒÚ© Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ ÛŒØ§ DataFrame Ø¨Ø§Ø´Ù†Ø¯.")

    # ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¯Ù†Ø¨Ø§Ù„Ù‡â€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ
    sequences, labels = create_sequences(df, sequence_length)

    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Tensor Ùˆ Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨Ù‡ GPU Ø¯Ø± ØµÙˆØ±Øª Ø§Ù…Ú©Ø§Ù†
    X = torch.tensor(sequences, dtype=torch.float32).to(device)
    y = torch.tensor(labels, dtype=torch.float32).to(device)

    # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ùˆ ØªØ³Øª
    train_size = int(0.8 * len(X))
    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]

    train_dataset = TensorDataset(X_train, y_train)
    test_dataset = TensorDataset(X_test, y_test)

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    # ØªØ¹ÛŒÛŒÙ† Ù…Ø¯Ù„
    input_size = X.shape[2]  # ØªØ¹Ø¯Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
    if model_type == "LSTM":
        model = LSTMModel(input_size, hidden_layer_size).to(device)  # hidden_layer_size Ø¨Ù‡ Ù…Ø¯Ù„ Ù…Ù†ØªÙ‚Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯
    elif model_type == "CNN":
        model = CNNModel(input_size).to(device)
    else:
        raise ValueError("Ù†ÙˆØ¹ Ù…Ø¯Ù„ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª. Ø§Ø² 'LSTM' ÛŒØ§ 'CNN' Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")

    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¢Ù…ÙˆØ²Ø´
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    # Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´
    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for X_batch, y_batch in train_loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)  # Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨Ù‡ GPU Ø¯Ø± ØµÙˆØ±Øª Ø§Ù…Ú©Ø§Ù†
            optimizer.zero_grad()
            output = model(X_batch)
            loss = criterion(output, y_batch)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        print(f"âœ… Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}")

    # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ù¾Ø³ Ø§Ø² Ø§ØªÙ…Ø§Ù… Ø¢Ù…ÙˆØ²Ø´
    model_save_path = "models/lstm_model.pth"
    os.makedirs("models", exist_ok=True)
    torch.save(model.state_dict(), model_save_path)
    print(f"âœ… Ù…Ø¯Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {model_save_path}")

    # **Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª**
    model.eval()
    total_test_loss = 0
    with torch.no_grad():
        for X_batch, y_batch in test_loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            output = model(X_batch)
            loss = criterion(output, y_batch)
            total_test_loss += loss.item()

    print(f"ğŸ“Š Test Loss: {total_test_loss / len(test_loader):.4f}")

    return model

# ØªØ³Øª Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø¯
if __name__ == "__main__":
    # Ù…Ø³ÛŒØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡ Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†
    data_path = "./data/processed/processed_data.csv"
    
    # Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    df = load_sensor_data(data_path)
    
    # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
    trained_model = train_model(df, model_type="LSTM", epochs=10, hidden_layer_size=128)  # Ù…Ù‚Ø¯Ø§Ø± hidden_layer_size Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ù†ÛŒØ¯
